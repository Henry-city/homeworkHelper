import streamlit as st
import pandas as pd
import hashlib
import re
import base64
import requests
import fitz  # PyMuPDF
from io import BytesIO

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="ä½œä¸šæŸ¥é‡ä¸æ™ºèƒ½æ‰¹æ”¹",
    page_icon="ğŸ“",
    layout="wide"
)

# --- CSS ç¾åŒ– ---
st.markdown("""
<style>
    .metric-card {
        background-color: #f0f2f6;
        border-radius: 10px;
        padding: 20px;
        text-align: center;
        border: 1px solid #e0e0e0;
    }
    .metric-value { font-size: 28px; font-weight: bold; color: #1f77b4; }
    .metric-label { color: #666; font-size: 14px; }
    .stDataFrame { border: 1px solid #eee; border-radius: 5px; }
    .stChatMessage { padding: 10px; border-radius: 5px; }
</style>
""", unsafe_allow_html=True)

# --- æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---

def get_md5(file_bytes):
    """è®¡ç®—æ–‡ä»¶ MD5"""
    m = hashlib.md5()
    m.update(file_bytes)
    return m.hexdigest()

def extract_id(text):
    """ä»å­—ç¬¦ä¸²ä¸­æå–9ä½æ•°å­—å­¦å·"""
    if not isinstance(text, str):
        text = str(text)
    match = re.search(r'\d{9}', text)
    return match.group() if match else None

def get_pdf_images_base64(file_bytes):
    """
    ã€å‡çº§ç‰ˆã€‘è¯»å– PDF çš„æ¯ä¸€é¡µï¼Œå¹¶è½¬æ¢ä¸º Base64 å›¾ç‰‡åˆ—è¡¨
    """
    images_b64 = []
    try:
        doc = fitz.open(stream=file_bytes, filetype="pdf")
        # å¾ªç¯å¤„ç†æ¯ä¸€é¡µ
        for page_num in range(len(doc)):
            page = doc[page_num]
            # 2å€ç¼©æ”¾ä»¥ä¿è¯ OCR æ¸…æ™°åº¦
            pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))
            img_data = pix.tobytes("png")
            b64_str = base64.b64encode(img_data).decode("utf-8")
            images_b64.append(b64_str)
        return images_b64
    except Exception as e:
        st.error(f"PDF è§£æå¤±è´¥: {e}")
        return []

def call_vl_ocr(api_key, file_bytes, filename):
    """
    è°ƒç”¨è§†è§‰å¤§æ¨¡å‹è¿›è¡Œ OCR (æ”¯æŒå¤šé¡µ)
    """
    # 1. å‡†å¤‡å›¾ç‰‡æ•°æ®åˆ—è¡¨
    base64_list = []
    
    if filename.lower().endswith('.pdf'):
        base64_list = get_pdf_images_base64(file_bytes)
        mime = "image/png"
    else:
        # å•å¼ å›¾ç‰‡å¤„ç†
        b64 = base64.b64encode(file_bytes).decode("utf-8")
        base64_list = [b64]
        mime = "image/jpeg"
        
    if not base64_list: return "âŒ æ— æ³•è¯»å–æ–‡ä»¶å›¾åƒ"

    url = "https://api.siliconflow.cn/v1/chat/completions"
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    
    # 2. æ„å»ºå¤šå›¾æ¶ˆæ¯ä½“
    content_payload = [{"type": "text", "text": "è¯·è¯†åˆ«ä»¥ä¸‹æ‰€æœ‰å›¾ç‰‡ä¸­çš„æ–‡å­—ï¼ŒæŒ‰é¡ºåºæ‹¼æ¥ï¼Œä¿æŒåŸæœ‰æ’ç‰ˆæ ¼å¼ï¼Œè¾“å‡º Markdownã€‚"}]
    
    # å°†æ¯ä¸€é¡µéƒ½åŠ è¿›å»
    for b64_img in base64_list:
        content_payload.append({
            "type": "image_url",
            "image_url": {"url": f"data:{mime};base64,{b64_img}"}
        })

    # ä½¿ç”¨ Qwen2-VL (è§†è§‰èƒ½åŠ›æœ€å¼º)
    payload = {
        "model": "Qwen/Qwen2-VL-72B-Instruct",
        "messages": [{"role": "user", "content": content_payload}],
        "temperature": 0.1,
        "max_tokens": 4096 
    }
    
    try:
        # å› ä¸ºå›¾ç‰‡å¤šï¼Œå¯èƒ½ä¼ è¾“æ…¢ï¼Œè®¾ç½®è¾ƒé•¿çš„è¶…æ—¶
        resp = requests.post(url, headers=headers, json=payload, timeout=180)
        if resp.status_code != 200: return f"OCR API é”™è¯¯ {resp.status_code}: {resp.text}"
        return resp.json()['choices'][0]['message']['content']
    except Exception as e:
        return f"OCR è¯·æ±‚å¼‚å¸¸: {str(e)}"

def call_ai_grader(api_key, content):
    """è°ƒç”¨ API è¿›è¡Œè¯„åˆ† (å·²åˆ‡æ¢ä¸ºæ›´å¿«çš„ Qwen2.5)"""
    url = "https://api.siliconflow.cn/v1/chat/completions"
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    payload = {
        # ğŸš€ åˆ‡æ¢ä¸º Qwen2.5-72Bï¼Œé€Ÿåº¦æ›´å¿«
        "model": "Qwen/Qwen2.5-72B-Instruct",
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸¥æ ¼çš„å¤§å­¦åŠ©æ•™ã€‚"},
            {"role": "user", "content": f"è¯·å¯¹ä»¥ä¸‹ä½œä¸šè¿›è¡Œè¯„åˆ†(0-100)å¹¶ç»™å‡ºç®€çŸ­è¯„è¯­ï¼š\n\n{content}"}
        ]
    }
    try:
        resp = requests.post(url, headers=headers, json=payload, timeout=60)
        return resp.json()['choices'][0]['message']['content']
    except:
        return "è¯„åˆ†æœåŠ¡è¶…æ—¶æˆ–å¤±è´¥"

def call_chat_bot(api_key, messages):
    """è°ƒç”¨ API è¿›è¡Œå¯¹è¯ (å·²åˆ‡æ¢ä¸ºæ›´å¿«çš„ Qwen2.5)"""
    url = "https://api.siliconflow.cn/v1/chat/completions"
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    payload = {
        # ğŸš€ åˆ‡æ¢ä¸º Qwen2.5-72B
        "model": "Qwen/Qwen2.5-72B-Instruct",
        "messages": messages,
        "stream": False 
    }
    try:
        resp = requests.post(url, headers=headers, json=payload, timeout=60)
        if resp.status_code != 200: return f"API æŠ¥é”™: {resp.text}"
        return resp.json()['choices'][0]['message']['content']
    except Exception as e:
        return f"å¯¹è¯è¿æ¥å¤±è´¥: {str(e)}"

# --- ä¸»ç¨‹åºé€»è¾‘ ---

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("ğŸ› ï¸ è®¾ç½®ä¸ä¸Šä¼ ")
    
    # --- ğŸ”‘ ç›´æ¥ä½¿ç”¨æ˜æ–‡ Keyï¼Œä¸å†æŠ¥é”™ ---
    default_key = "sk-mbmefdriwcavkosajtsgssddeerqiccggiuxmysydsnalghm"
    api_key = st.text_input("SiliconFlow API Key", value=default_key, type="password")
    
    st.divider()
    
    roster_file = st.file_uploader("1. ä¸Šä¼ èŠ±åå†Œ (Excel)", type=['xlsx', 'xls'])
    homework_files = st.file_uploader("2. ä¸Šä¼ ä½œä¸šæ–‡ä»¶", accept_multiple_files=True)
    
    st.info("æç¤ºï¼šèŠ±åå†Œå¿…é¡»åŒ…å«ä¸€åˆ—9ä½æ•°å­—çš„å­¦å·ã€‚")

# ä¸»ç•Œé¢
st.title("ğŸ“Š ä½œä¸šæ£€æŸ¥çœ‹æ¿")

if not roster_file:
    st.warning("ğŸ‘ˆ è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼ ã€èŠ±åå†Œ Excelã€‘")
    st.stop()

# 1. å¤„ç†èŠ±åå†Œ
try:
    df_roster = pd.read_excel(roster_file, dtype=str)
    roster_dict = {} 
    for idx, row in df_roster.iterrows():
        row_str = " ".join(row.fillna("").astype(str).values)
        sid = extract_id(row_str)
        if sid:
            name = "æœªçŸ¥å§“å"
            for item in row.values:
                item = str(item).strip()
                if item != sid and not item.isdigit() and len(item) >= 2:
                    name = item
                    break
            roster_dict[sid] = name
    all_students = set(roster_dict.keys())
    if not all_students:
        st.error("âŒ èŠ±åå†Œè¯»å–å¤±è´¥ï¼šæœªæ‰¾åˆ°ä»»ä½•9ä½å­¦å·ã€‚")
        st.stop()
except Exception as e:
    st.error(f"Excel è¯»å–é”™è¯¯: {e}")
    st.stop()

# 2. å¤„ç†ä½œä¸šæ–‡ä»¶
submitted_data = []
files_map = {}
md5_map = {}
empty_files = []

if homework_files:
    for f in homework_files:
        fname = f.name
        if fname.startswith("~$") or fname.startswith("."): continue
        sid = extract_id(fname)
        if sid and sid in all_students:
            files_map[fname] = f
            f_bytes = f.getvalue()
            f_size = f.size
            submitted_data.append(sid)
            if f_size < 100:
                empty_files.append({"å­¦å·": sid, "å§“å": roster_dict[sid], "æ–‡ä»¶å": fname, "å¤§å°": f"{f_size}B"})
            else:
                f_md5 = get_md5(f_bytes)
                if f_md5 not in md5_map: md5_map[f_md5] = []
                md5_map[f_md5].append((sid, fname))

# 3. ç»Ÿè®¡è®¡ç®—
submitted_ids = set(submitted_data)
missing_ids = all_students - submitted_ids
submit_rate = round(len(submitted_ids) / len(all_students) * 100, 1)

# 4. æ˜¾ç¤ºé¡¶éƒ¨æŒ‡æ ‡
c1, c2, c3, c4 = st.columns(4)
c1.markdown(f"<div class='metric-card'><div class='metric-value'>{len(all_students)}</div><div class='metric-label'>åº”äº¤äººæ•°</div></div>", unsafe_allow_html=True)
c2.markdown(f"<div class='metric-card'><div class='metric-value'>{len(submitted_ids)}</div><div class='metric-label'>å®äº¤äººæ•°</div></div>", unsafe_allow_html=True)
c3.markdown(f"<div class='metric-card'><div class='metric-value' style='color:#d62728'>{len(missing_ids)}</div><div class='metric-label'>æœªäº¤äººæ•°</div></div>", unsafe_allow_html=True)
c4.markdown(f"<div class='metric-card'><div class='metric-value'>{submit_rate}%</div><div class='metric-label'>æäº¤ç‡</div></div>", unsafe_allow_html=True)

st.write("") 

# 5. åŠŸèƒ½é€‰é¡¹å¡
tab1, tab2, tab3 = st.tabs(["ğŸ“‹ åå•è¯¦æƒ…", "ğŸ” å¼‚å¸¸æ£€æµ‹", "ğŸ¤– AI æ™ºèƒ½æ‰¹æ”¹ + ç­”ç–‘"])

with tab1:
    col_missing, col_submitted = st.columns(2)
    with col_missing:
        st.subheader("âŒ æœªäº¤åå•")
        if missing_ids:
            missing_list = [{"å­¦å·": sid, "å§“å": roster_dict[sid]} for sid in sorted(missing_ids)]
            st.dataframe(missing_list, use_container_width=True, hide_index=True)
        else:
            st.success("ğŸ‰ æ‰€æœ‰äººå‡å·²æäº¤ï¼")
    with col_submitted:
        st.subheader("âœ… å·²äº¤åå•")
        if submitted_ids:
            with st.expander("ç‚¹å‡»æŸ¥çœ‹å·²äº¤è¯¦æƒ…"):
                st.write(f"å…± {len(submitted_ids)} äºº")
                st.write(", ".join([f"{roster_dict[sid]}" for sid in submitted_ids]))
        else:
            st.info("æš‚æ— æäº¤æ•°æ®")

with tab2:
    col_dup, col_empty = st.columns(2)
    with col_dup:
        st.subheader("ğŸ‘¯ ç–‘ä¼¼é›·åŒ")
        dup_groups = [v for k, v in md5_map.items() if len(v) > 1]
        if not dup_groups:
            st.success("âœ… æœªå‘ç°é›·åŒæ–‡ä»¶")
        else:
            for i, group in enumerate(dup_groups, 1):
                st.warning(f"é›·åŒç»„ #{i} (å…±{len(group)}äºº)")
                for sid, fname in group:
                    st.text(f"- {sid} {roster_dict[sid]} : {fname}")
    with col_empty:
        st.subheader("ğŸ“„ å¼‚å¸¸/ç©ºæ–‡ä»¶")
        if not empty_files:
            st.success("âœ… æ–‡ä»¶å¤§å°æ­£å¸¸")
        else:
            st.dataframe(empty_files, use_container_width=True)

with tab3:
    st.subheader("ğŸ¤– Qwen2.5 æ™ºèƒ½æ‰¹æ”¹ & äº’åŠ¨")
    
    pdf_candidates = [f for f in files_map.keys() if f.lower().endswith('.pdf')]
    
    if not pdf_candidates:
        st.warning("âš ï¸ è¯·ä¸Šä¼  PDF æ ¼å¼çš„ä½œä¸šä»¥ä½¿ç”¨æ­¤åŠŸèƒ½")
    else:
        sel_file = st.selectbox("é€‰æ‹©è¦æ‰¹æ”¹çš„ä½œä¸š:", pdf_candidates)
        
        # --- ä¼šè¯çŠ¶æ€ç®¡ç† ---
        if "last_sel_file" not in st.session_state:
            st.session_state.last_sel_file = sel_file
        
        # å¦‚æœåˆ‡æ¢äº†æ–‡ä»¶ï¼Œé‡ç½®çŠ¶æ€
        if st.session_state.last_sel_file != sel_file:
            st.session_state.current_analysis = None
            st.session_state.chat_messages = []
            st.session_state.last_sel_file = sel_file

        if "current_analysis" not in st.session_state:
            st.session_state.current_analysis = None
        if "chat_messages" not in st.session_state:
            st.session_state.chat_messages = []

        # --- æŒ‰é’®ä¸æ ¸å¿ƒé€»è¾‘ ---
        if st.button("ğŸš€ å¼€å§‹å…¨é¡µåˆ†æ", type="primary"):
            target_f = files_map[sel_file]
            target_f.seek(0)
            file_data = target_f.read()
            
            with st.status("AI æ­£åœ¨å…¨åŠ›å¤„ç†...", expanded=True) as status:
                st.write("ğŸ‘€ æ­£åœ¨é˜…è¯»ä½œä¸šæ‰€æœ‰é¡µé¢ (å¤šé¡µOCR)...")
                # è°ƒç”¨å¤šé¡µOCR
                ocr_res = call_vl_ocr(api_key, file_data, sel_file)
                
                if "âŒ" in ocr_res or "API é”™è¯¯" in ocr_res:
                    status.update(label="å¤„ç†å¤±è´¥", state="error")
                    st.error(ocr_res)
                else:
                    st.write("ğŸ§  æ­£åœ¨è¯„åˆ† (Qwen2.5)...")
                    eval_res = call_ai_grader(api_key, ocr_res)
                    status.update(label="åˆ†æå®Œæˆ", state="complete")
                    
                    st.session_state.current_analysis = {
                        "ocr": ocr_res,
                        "eval": eval_res
                    }
                    st.session_state.chat_messages = []

        # --- ç»“æœä¸èŠå¤© ---
        if st.session_state.current_analysis:
            data = st.session_state.current_analysis
            
            st.divider()
            c_left, c_right = st.columns(2)
            with c_left:
                st.markdown("#### ğŸ“„ ä½œä¸šè¯†åˆ«å†…å®¹ (å…¨éƒ¨é¡µé¢)")
                st.text_area("", data["ocr"], height=300, disabled=True)
            with c_right:
                st.markdown("#### ğŸ“ è¯„ä»·æŠ¥å‘Š")
                st.markdown(data["eval"])
            
            st.divider()
            st.subheader("ğŸ’¬ ä½œä¸šåŠ©æ‰‹ Qwen")
            st.caption("åŸºäºè¿™ä»½ä½œä¸šå†…å®¹ï¼Œæ‚¨å¯ä»¥é—®ï¼šè¿™é“é¢˜ä¸ºä»€ä¹ˆé”™äº†ï¼Ÿå¦‚ä½•æ”¹è¿›ï¼Ÿ")

            for msg in st.session_state.chat_messages:
                with st.chat_message(msg["role"]):
                    st.markdown(msg["content"])

            if prompt := st.chat_input("è¾“å…¥é—®é¢˜..."):
                st.session_state.chat_messages.append({"role": "user", "content": prompt})
                with st.chat_message("user"):
                    st.markdown(prompt)

                system_prompt = f"""
                ä½ æ˜¯ä¸€ä¸ªä½œä¸šè¾…å¯¼åŠ©æ‰‹ã€‚
                ã€ä½œä¸šå…¨æ–‡å†…å®¹ã€‘ï¼š
                {data['ocr']}
                
                ã€è¯„åˆ†ç»“æœã€‘ï¼š
                {data['eval']}
                
                è¯·åŸºäºä»¥ä¸Šä¿¡æ¯å›ç­”ç”¨æˆ·æé—®ã€‚
                """
                
                api_messages = [{"role": "system", "content": system_prompt}] + st.session_state.chat_messages

                with st.chat_message("assistant"):
                    with st.spinner("æ€è€ƒä¸­..."):
                        response = call_chat_bot(api_key, api_messages)
                        st.markdown(response)
                
                st.session_state.chat_messages.append({"role": "assistant", "content": response})

with st.expander("ğŸ› ï¸ è°ƒè¯•é¢æ¿"):
    st.write(f"èŠ±åå†Œè§£æäººæ•°: {len(all_students)}")
    st.write(f"ä¸Šä¼ æ–‡ä»¶æ•°: {len(homework_files) if homework_files else 0}")