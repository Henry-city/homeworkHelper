import streamlit as st
import pandas as pd
import hashlib
import re
import base64
import requests
import fitz  # PyMuPDF
from io import BytesIO

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="ä½œä¸šæŸ¥é‡ä¸æ™ºèƒ½æ‰¹æ”¹",
    page_icon="ğŸ“",
    layout="wide"
)

# --- CSS ç¾åŒ– ---
st.markdown("""
<style>
    .metric-card {
        background-color: #f0f2f6;
        border-radius: 10px;
        padding: 20px;
        text-align: center;
        border: 1px solid #e0e0e0;
    }
    .metric-value { font-size: 28px; font-weight: bold; color: #1f77b4; }
    .metric-label { color: #666; font-size: 14px; }
    .stDataFrame { border: 1px solid #eee; border-radius: 5px; }
</style>
""", unsafe_allow_html=True)

# --- æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---

def get_md5(file_bytes):
    """è®¡ç®—æ–‡ä»¶ MD5"""
    m = hashlib.md5()
    m.update(file_bytes)
    return m.hexdigest()

def extract_id(text):
    """ä»å­—ç¬¦ä¸²ä¸­æå–9ä½æ•°å­—å­¦å·"""
    if not isinstance(text, str):
        text = str(text)
    match = re.search(r'\d{9}', text)
    return match.group() if match else None

def pdf_to_image_base64(file_bytes):
    """PDFé¦–é¡µè½¬å›¾ç‰‡Base64 (ä¿®å¤APIæ ¼å¼æŠ¥é”™)"""
    try:
        doc = fitz.open(stream=file_bytes, filetype="pdf")
        if len(doc) < 1: return None
        page = doc[0]
        pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))
        return base64.b64encode(pix.tobytes("png")).decode("utf-8")
    except Exception as e:
        return None

def call_deepseek_ocr(api_key, file_bytes, filename):
    """è°ƒç”¨ API è¿›è¡Œ OCR"""
    if filename.lower().endswith('.pdf'):
        b64_img = pdf_to_image_base64(file_bytes)
        mime = "image/png"
    else:
        b64_img = base64.b64encode(file_bytes).decode("utf-8")
        mime = "image/jpeg"
        
    if not b64_img: return "âŒ æ— æ³•å¤„ç†æ–‡ä»¶å›¾åƒ"

    url = "https://api.siliconflow.cn/v1/chat/completions"
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    
    # ä½¿ç”¨ Qwen2-VL è¿›è¡Œè§†è§‰è¯†åˆ«
    payload = {
        "model": "Qwen/Qwen2-VL-72B-Instruct",
        "messages": [{
            "role": "user",
            "content": [
                {"type": "image_url", "image_url": {"url": f"data:{mime};base64,{b64_img}"}},
                {"type": "text", "text": "è¯†åˆ«å›¾ç‰‡ä¸­çš„æ‰€æœ‰æ–‡å­—ï¼Œä¿æŒæ’ç‰ˆï¼Œè¾“å‡º Markdownã€‚"}
            ]
        }],
        "temperature": 0.1,
        "max_tokens": 2048
    }
    try:
        resp = requests.post(url, headers=headers, json=payload, timeout=60)
        if resp.status_code != 200: return f"API é”™è¯¯ {resp.status_code}: {resp.text}"
        return resp.json()['choices'][0]['message']['content']
    except Exception as e:
        return f"è¯·æ±‚å¼‚å¸¸: {str(e)}"

def call_ai_grader(api_key, content):
    """è°ƒç”¨ API è¿›è¡Œè¯„åˆ†"""
    url = "https://api.siliconflow.cn/v1/chat/completions"
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    payload = {
        "model": "deepseek-ai/DeepSeek-V3",
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸¥æ ¼çš„å¤§å­¦åŠ©æ•™ã€‚"},
            {"role": "user", "content": f"è¯·å¯¹ä»¥ä¸‹ä½œä¸šè¿›è¡Œè¯„åˆ†(0-100)å¹¶ç»™å‡ºç®€çŸ­è¯„è¯­ï¼š\n\n{content}"}
        ]
    }
    try:
        resp = requests.post(url, headers=headers, json=payload, timeout=30)
        return resp.json()['choices'][0]['message']['content']
    except:
        return "è¯„åˆ†æœåŠ¡è¿æ¥å¤±è´¥"

# --- ä¸»ç¨‹åºé€»è¾‘ ---

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("ğŸ› ï¸ è®¾ç½®ä¸ä¸Šä¼ ")
    api_key = st.text_input("API Key", value="sk-mbmefdriwcavkosajtsgssddeerqiccggiuxmysydsnalghm", type="password")
    st.divider()
    
    roster_file = st.file_uploader("1. ä¸Šä¼ èŠ±åå†Œ (Excel)", type=['xlsx', 'xls'])
    homework_files = st.file_uploader("2. ä¸Šä¼ ä½œä¸šæ–‡ä»¶", accept_multiple_files=True)
    
    st.info("æç¤ºï¼šèŠ±åå†Œå¿…é¡»åŒ…å«ä¸€åˆ—9ä½æ•°å­—çš„å­¦å·ã€‚")

# ä¸»ç•Œé¢
st.title("ğŸ“Š ä½œä¸šæ£€æŸ¥çœ‹æ¿")

if not roster_file:
    st.warning("ğŸ‘ˆ è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼ ã€èŠ±åå†Œ Excelã€‘")
    st.stop()

# 1. å¤„ç†èŠ±åå†Œ (å…³é”®ä¿®å¤ï¼šå¼ºåˆ¶è½¬å­—ç¬¦ä¸²)
try:
    # dtype=str å¼ºåˆ¶æ‰€æœ‰å†…å®¹è¯»å–ä¸ºæ–‡æœ¬ï¼Œé˜²æ­¢æ•°å­—/å­—ç¬¦ä¸²ä¸åŒ¹é…
    df_roster = pd.read_excel(roster_file, dtype=str)
    
    roster_dict = {} # å­¦å· -> å§“å
    for idx, row in df_roster.iterrows():
        # å°†æ•´è¡Œè½¬ä¸ºå­—ç¬¦ä¸²æœç´¢
        row_str = " ".join(row.fillna("").astype(str).values)
        sid = extract_id(row_str)
        if sid:
            # å°è¯•æ‰¾å§“åï¼šæ’é™¤å­¦å·æœ¬èº«å’Œçº¯æ•°å­—ï¼Œæ‰¾å‰©ä¸‹çš„è¾ƒçŸ­å­—ç¬¦ä¸²
            name = "æœªçŸ¥å§“å"
            for item in row.values:
                item = str(item).strip()
                if item != sid and not item.isdigit() and len(item) >= 2:
                    name = item
                    break
            roster_dict[sid] = name

    all_students = set(roster_dict.keys())
    
    if not all_students:
        st.error("âŒ èŠ±åå†Œè¯»å–å¤±è´¥ï¼šæœªæ‰¾åˆ°ä»»ä½•9ä½å­¦å·ï¼Œè¯·æ£€æŸ¥Excelæ ¼å¼ã€‚")
        st.dataframe(df_roster.head()) # å±•ç¤ºå‰å‡ è¡Œå¸®åŠ©è°ƒè¯•
        st.stop()
        
except Exception as e:
    st.error(f"Excel è¯»å–é”™è¯¯: {e}")
    st.stop()

# 2. å¤„ç†ä½œä¸šæ–‡ä»¶
submitted_data = []  # å­˜å‚¨å·²äº¤ä½œä¸šä¿¡æ¯
files_map = {}       # æ–‡ä»¶å -> æ–‡ä»¶å¯¹è±¡
md5_map = {}         # MD5 -> [å­¦å·åˆ—è¡¨]
empty_files = []     # ç©ºæ–‡ä»¶åˆ—è¡¨

if homework_files:
    for f in homework_files:
        fname = f.name
        # è¿‡æ»¤ä¸´æ—¶æ–‡ä»¶
        if fname.startswith("~$") or fname.startswith("."): continue
        
        # æå–å­¦å·
        sid = extract_id(fname)
        
        # åªè¦æ–‡ä»¶åé‡Œæœ‰å­¦å·ï¼Œå¹¶ä¸”å­¦å·åœ¨èŠ±åå†Œé‡Œï¼Œå°±ç®—å·²äº¤
        if sid and sid in all_students:
            # ä¿å­˜æ–‡ä»¶å¼•ç”¨
            files_map[fname] = f
            f_bytes = f.getvalue()
            f_size = f.size
            
            # è®°å½•æäº¤
            submitted_data.append(sid)
            
            # å¼‚å¸¸æ£€æµ‹ï¼šç©ºæ–‡ä»¶
            if f_size < 100:
                empty_files.append({"å­¦å·": sid, "å§“å": roster_dict[sid], "æ–‡ä»¶å": fname, "å¤§å°": f"{f_size}B"})
            else:
                # å¼‚å¸¸æ£€æµ‹ï¼šæŸ¥é‡
                f_md5 = get_md5(f_bytes)
                if f_md5 not in md5_map: md5_map[f_md5] = []
                md5_map[f_md5].append((sid, fname))

# 3. ç»Ÿè®¡è®¡ç®—
submitted_ids = set(submitted_data)
missing_ids = all_students - submitted_ids
submit_rate = round(len(submitted_ids) / len(all_students) * 100, 1)

# 4. æ˜¾ç¤ºé¡¶éƒ¨æŒ‡æ ‡
c1, c2, c3, c4 = st.columns(4)
c1.markdown(f"<div class='metric-card'><div class='metric-value'>{len(all_students)}</div><div class='metric-label'>åº”äº¤äººæ•°</div></div>", unsafe_allow_html=True)
c2.markdown(f"<div class='metric-card'><div class='metric-value'>{len(submitted_ids)}</div><div class='metric-label'>å®äº¤äººæ•°</div></div>", unsafe_allow_html=True)
c3.markdown(f"<div class='metric-card'><div class='metric-value' style='color:#d62728'>{len(missing_ids)}</div><div class='metric-label'>æœªäº¤äººæ•°</div></div>", unsafe_allow_html=True)
c4.markdown(f"<div class='metric-card'><div class='metric-value'>{submit_rate}%</div><div class='metric-label'>æäº¤ç‡</div></div>", unsafe_allow_html=True)

st.write("") # é—´è·

# 5. åŠŸèƒ½é€‰é¡¹å¡
tab1, tab2, tab3 = st.tabs(["ğŸ“‹ åå•è¯¦æƒ…", "ğŸ” å¼‚å¸¸æ£€æµ‹", "ğŸ¤– AI æ™ºèƒ½æ‰¹æ”¹"])

with tab1:
    col_missing, col_submitted = st.columns(2)
    
    with col_missing:
        st.subheader("âŒ æœªäº¤åå•")
        if missing_ids:
            # æ„å»ºè¡¨æ ¼æ•°æ®
            missing_list = [{"å­¦å·": sid, "å§“å": roster_dict[sid]} for sid in sorted(missing_ids)]
            st.dataframe(missing_list, use_container_width=True, hide_index=True)
        else:
            st.success("ğŸ‰ å¤ªæ£’äº†ï¼Œæ‰€æœ‰äººå‡å·²æäº¤ï¼")
            
    with col_submitted:
        st.subheader("âœ… å·²äº¤åå•")
        if submitted_ids:
            with st.expander("ç‚¹å‡»æŸ¥çœ‹å·²äº¤è¯¦æƒ…"):
                st.write(f"å…± {len(submitted_ids)} äºº")
                st.write(", ".join([f"{roster_dict[sid]}" for sid in submitted_ids]))
        else:
            st.info("æš‚æ— æäº¤æ•°æ®")

with tab2:
    col_dup, col_empty = st.columns(2)
    
    with col_dup:
        st.subheader("ğŸ‘¯ ç–‘ä¼¼é›·åŒ (å†…å®¹å®Œå…¨ä¸€è‡´)")
        # è¿‡æ»¤å‡ºåªæœ‰1ä¸ªäººçš„ç»„ï¼ˆå³æ— é›·åŒï¼‰
        dup_groups = [v for k, v in md5_map.items() if len(v) > 1]
        
        if not dup_groups:
            st.success("âœ… æœªå‘ç°é›·åŒæ–‡ä»¶")
        else:
            for i, group in enumerate(dup_groups, 1):
                st.warning(f"é›·åŒç»„ #{i} (å…±{len(group)}äºº)")
                for sid, fname in group:
                    st.text(f"- {sid} {roster_dict[sid]} : {fname}")

    with col_empty:
        st.subheader("ğŸ“„ å¼‚å¸¸/ç©ºæ–‡ä»¶")
        if not empty_files:
            st.success("âœ… æ–‡ä»¶å¤§å°å‡æ­£å¸¸")
        else:
            st.dataframe(empty_files, use_container_width=True)

with tab3:
    st.subheader("ğŸ¤– DeepSeek æ™ºèƒ½æ‰¹æ”¹")
    st.caption("æ”¯æŒå¯¹ PDF æ–‡ä»¶è¿›è¡Œ OCR è¯†åˆ«å¹¶è‡ªåŠ¨è¯„ä»·")
    
    # ç­›é€‰PDF
    pdf_candidates = [f for f in files_map.keys() if f.lower().endswith('.pdf')]
    
    if not pdf_candidates:
        st.warning("âš ï¸ è¯·ä¸Šä¼  PDF æ ¼å¼çš„ä½œä¸šä»¥ä½¿ç”¨æ­¤åŠŸèƒ½")
    else:
        sel_file = st.selectbox("é€‰æ‹©è¦æ‰¹æ”¹çš„ä½œä¸š:", pdf_candidates)
        
        if st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary"):
            target_f = files_map[sel_file]
            target_f.seek(0)
            file_data = target_f.read()
            
            # æ­¥éª¤1ï¼šOCR
            with st.status("æ­£åœ¨è¿›è¡Œ AI å¤„ç†...", expanded=True) as status:
                st.write("ğŸ‘€ æ­£åœ¨é˜…è¯»æ–‡æ¡£ (OCR)...")
                ocr_res = call_deepseek_ocr(api_key, file_data, sel_file)
                
                if "âŒ" in ocr_res or "API é”™è¯¯" in ocr_res:
                    status.update(label="å¤„ç†å¤±è´¥", state="error")
                    st.error(ocr_res)
                else:
                    st.write("ğŸ§  æ­£åœ¨æ€è€ƒè¯„åˆ† (DeepSeek-V3)...")
                    eval_res = call_ai_grader(api_key, ocr_res)
                    status.update(label="å¤„ç†å®Œæˆ", state="complete")
                    
                    st.divider()
                    c_left, c_right = st.columns([1, 1])
                    with c_left:
                        st.markdown("#### ğŸ“„ è¯†åˆ«å†…å®¹")
                        st.text_area("", ocr_res, height=300)
                    with c_right:
                        st.markdown("#### ğŸ“ è¯„ä»·æŠ¥å‘Š")
                        st.markdown(eval_res)

# è°ƒè¯•ä¿¡æ¯ (å¦‚æœè¿˜æ˜¯ä¸æ˜¾ç¤ºï¼Œå¯ä»¥å±•å¼€è¿™ä¸ªçœ‹åŸå› )
with st.expander("ğŸ› ï¸ è°ƒè¯•é¢æ¿ (å¦‚æœæ•°æ®ä¸æ˜¾ç¤ºè¯·ç‚¹è¿™é‡Œ)"):
    st.write(f"èŠ±åå†Œè§£æäººæ•°: {len(all_students)}")
    if all_students:
        st.write(f"èŠ±åå†Œæ ·ä¾‹å­¦å·: {list(all_students)[0]} (ç±»å‹: {type(list(all_students)[0])})")
    st.write(f"ä¸Šä¼ æ–‡ä»¶æ•°: {len(homework_files) if homework_files else 0}")